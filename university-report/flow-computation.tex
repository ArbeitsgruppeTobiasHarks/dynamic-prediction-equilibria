\section{Computation of Dynamic Prediction Equilibria}\label{sec:compute-dpes}

In this section we want to discuss how we can compute an approximated variant of DPEs.
We recall from the definition, that in a DPE all infinitesimally small agents update their routing decision every time they arrive at an intermediate node.
As we are dealing with continuous flows, these routing decisions take place in a continuous manner.
To approximate this, we choose to allow updates of the routing decisions to happen at predefined intervals.
This leads to the following definition:

\begin{definition}
    Let $\varepsilon > 0$.
    A pair $(\predq, f)$ of a set of predictors $(\predq_{i,e})_{i\in I, e\in E}$ and a dynamic flow $f$ is a \emph{partial $\varepsilon$-approximated dynamic prediction equilibrium ($\varepsilon$-DPE) up to time $H\in\R\cup\{\infty\}$} if $f$ is feasible up to time $H$ and for all $e\in E, i\in I$ and $\theta < H$ it holds that
    \[
        \infl_{i,e}(\theta) > 0 \implies e \in \predE_i(\varepsilon\cdot \left\lfloor{\theta / \varepsilon}\right\rfloor, \varepsilon\cdot \left\lfloor{\theta / \varepsilon}\right\rfloor, q).
    \]
\end{definition}

To compute these kinds of dynamic flows, we begin by setting up the data structures representing dynamic flows before we have a look at the extension of feasible flows and finally how to use the predictors and the computation of dynamic shortest paths to extend the flows following the prescript in the definition of $\varepsilon$-DPEs.

Moreover, we focus on dynamic flows with right-constant flow rates only.
This means, we assume that all network inflow rates $u_i$ are right-constant.

\subsection{Extension Theorem}

Before diving into an actual program, we first consider a few theoretical observations involving the feasibility of dynamic flows.
More specifically, we want to extend partial flows with constant edge inflow rates while always preserving the feasibility properties \ref{def:feasible-flow:max-capacity}, \ref{def:feasible-flow:deterministic-split} and~\ref{def:feasible-flow:operate-at-capacity}.
By choosing appropriate edge inflow rates, we will later make sure that the flow conservation property~\ref{def:feasible-flow:flow-conservation} is fulfilled as well. 
The following theorem is the building block for the algorithms introduced in the next sections.

\begin{theorem}\label{thm:extend-edge}
    Let $f$ be a dynamic flow fulfilling properties~\ref{def:feasible-flow:max-capacity}, \ref{def:feasible-flow:deterministic-split} and~\ref{def:feasible-flow:operate-at-capacity} on an edge $e\in E$ for almost all $\theta\in\R$.
    We are given new constant inflow rates $(g_{i,e})_{i\in I}\in\R_{\geq0}^{I}$ into $e$ beginning from time $\phi$ and let $g_e \coloneqq \sum_{i\in I} g_{i,e}$.
    We partially reassign $\infl_{i,e}$ using $\restrict{\infl_{i,e}}{[\phi,\infty)} \colonequiv g_{i,e}$ for all $i\in I$.
    Moreover, we partially update $\outfl_{i,e}$ in the following manner:
    \begin{enumerate}[label=\textbf{Case \Roman*.}, wide=0.5em, labelwidth=4.5em]
        \item If $g_e = 0$, we set $\restrict{\outfl_{i,e}}{[T_e(\phi), \infty)} \colonequiv 0$.
        
        \item If $g_e > 0 \,\land\, \left( q_e(\phi) = 0 \,\lor\, g_e \geq \capa_e \right)$, we assign $\restrict{\outfl_{i,e}}{[T_e(\phi), \infty)} \colonequiv \min\{\capa_e, g_e\}\cdot \frac{g_{i,e}}{g_e}$.
        
        \item If $g_e \in (0, \capa_e) \,\land\, q_e(\phi) > 0$, we use $T_{\depl} \coloneqq \phi + \frac{q_e(\phi)}{\capa_e - g_e}$ for assigning
        \begin{align*}
            \restrict{\outfl_{i,e}}{[T_e(\phi), T_{\depl} + \transit_e)}
            \colonequiv \capa_e \cdot \frac{g_{i,e}}{g_e}
            \quad\text{and}\quad
            \restrict{\outfl_{i,e}}{[T_{\depl} + \transit_e, \infty)}
            \colonequiv g_{i,e}.
        \end{align*}
    \end{enumerate}
    Then the updated dynamic flow $f$ still fulfills the properties \ref{def:feasible-flow:max-capacity}, \ref{def:feasible-flow:deterministic-split} and~\ref{def:feasible-flow:operate-at-capacity} on edge $e$ for almost all $\theta\in \R$.
\end{theorem}
\begin{proof}
    Let $f$ be the original and $h$ be the transformed dynamic flow and let $q^f$ and $q^h$ denote their corresponding queue length functions.
    We note, that $q^f$ and $q^h$ as well as $T^f$ and $T^h$ coincide on $(-\infty, \phi]$.
    Moreover, the outflow rate $\outfl[h]_e$ never exceeds $\capa_e$ and hence~\ref{def:feasible-flow:max-capacity} is fulfilled right away.
    Next, we show~\ref{def:feasible-flow:operate-at-capacity}, i.e. \[
        \outfl[h]_e(\theta) = \begin{cases}
            \capa_e, &\text{if $q^h_e(\theta - \transit_e) > 0$,} \\
            \infl[h]_e(\theta - \transit_e), &\text{otherwise.}
        \end{cases}
    \]
    For $\theta < \phi + \transit_e$, this follows solely from the properties of $f$.
    Let us analyze the case $\phi + \transit_e \leq \theta < T_e(\phi)$ or equivalently $\phi  \leq \theta - \transit_e < \phi + q_e(\phi) /\capa_e$.
    With~\ref{def:feasible-flow:max-capacity} we conclude \begin{align*}
        q_e^h(\theta - \transit_e)
        &= \int_0^{\theta-\transit_e} \infl[h]_e(\psi) \diff \psi - \int_0^{\theta} \outfl[h]_e(\psi) \diff \psi \\
        &\geq \int_0^{\phi} \infl[h]_e(\psi)\diff \psi - \int_0^{\phi + \transit_e} \outfl[h]_e(\psi) \diff \psi
        - \capa_e\cdot (\theta - \transit_e - \phi)\\
        & = q_e(\phi) - \capa_e\cdot(\theta - \transit_e - \phi) >  0.
    \end{align*}
    With the same reasoning we infer $q_e^f(\theta - \transit_e) > 0$ and therefore $\outfl[h]_e(\theta) = \outfl[f]_e(\theta) = \capa_e$.
    Let us finally discuss the case $\theta > T_e(\phi)$;
    the point $\theta = T_e(\phi)$ can be ignored as we are only interested in almost all times.
    We distinguish between the three cases:
    \begin{enumerate}[label=\textbf{Case \Roman*.}, wide=0.5em]
        \item Here, $g_e = 0$ implies \begin{align*}
            q_e^h(\theta - \transit_e)
            = \int_0^\phi \infl[h]_e(\psi) \diff \psi - \int_0^{T_e(\phi)} \outfl[h]_e(\psi)\diff \psi
            = q_e(\phi) - \int_\phi^{\phi + q_e(\phi)/\capa_e} \outfl[h]_e(\psi + \transit_e)\diff \psi
        \end{align*}
        And as property~\ref{def:feasible-flow:operate-at-capacity} holds for $t\leq T_e(\theta)$, we infer $q_e^h(\theta - \transit_e) = q_e(\phi) - \capa_e \cdot \frac{q_e(\phi)}{\capa_e} = 0$.
        Together with $\outfl[h]_e(\theta) = 0 = \infl[h]_e(\theta - \transit_e)$ this yields the claim.

        \item We have $g_e > 0 \,\land\, \left( q_e(\phi) = 0 \,\lor\, g_e \geq \capa_e \right)$.
        Then \begin{align*}
            q_e^h(\theta - \transit_e) &= q_e(\phi) + g_e \cdot (\theta - \transit_e - \phi) - \int_{\phi + \transit_e}^{\theta} \outfl[h]_e(\psi)\diff \psi \\
            &= q_e(\phi) + g_e\cdot (\theta - \transit_e - \phi) - q_e(\phi) - (\theta - T_e(\phi))\cdot \min\{\capa_e, g_e\} \\
            &= g_e\cdot(\theta -\transit_e - \phi) - (\theta - T_e(\phi))\cdot \min\{\capa_e, g_e\}.
        \end{align*}
        Let us first assume $q_e(\phi) = 0$.
        Then the above reduces to $(g_e - \min\{\capa_e,g_e\})\cdot (\theta - T_e(\phi))$ which is positive if and only if $g_e > \capa_e$ holds.
        In that case $\outfl[h]_e(\theta) = \capa_e$ holds by our assignment.
        If $q_e^h(\theta - \transit_e)$ is non-positive, we have $g_e \leq \capa_e$ which implies $\outfl[h]_e(\theta) = g_e = \infl[h]_e(\theta - \transit_e)$.

        For the case $q_e(\phi) > 0$ and $g_e \geq \capa_e$, we have \[
            q_e^h(\theta - \transit_e) = g_e\cdot(\theta - \transit_e - \phi) - (\theta - T_e(\phi)) \cdot \capa_e = (g_e - \capa_e) \cdot (\theta - \transit_e - \phi) + q_e(\phi) > 0
        \]
        and then the claim follows from $\outfl[h]_e(\theta) = \capa_e$.

        \item We do a case distinction on $\theta - \transit_e < T_{\depl}$.
        If this is true, then \begin{align*}
            q^h_e (\theta - \transit_e)
            &= q_e(\phi) + g_e\cdot (\theta-\transit_e-\phi) - \capa_e\cdot (\theta - \phi - \transit_e)\\
            &= q_e(\phi) - (\capa_e - g_e) \cdot (\theta - \transit_e - \phi)
            > q_e(\phi) - (\capa_e - g_e) \cdot (T_{\depl} - \phi) = 0.
        \end{align*}
        Moreover, we have $\outfl[h](\theta) = \capa_e$ in this case.
        Finally, for $\theta - \transit_e \geq T_{\depl}$ we have
        \begin{align*}
            q^h_e (\theta - \transit_e)
            &= q^h_e(T_{\depl}) + g_e \cdot (\theta - \transit_e - T_{\depl}) - g_e \cdot (\theta - T_{\depl} - \transit_e) = q^h_e(T_{\depl})
        \end{align*}
        and by the arguments above we deduce $q^h_e(T_{\depl}) = 0$.
        As $\outfl[h]_e(\theta) = g_e = \infl[h]_e(\theta - \transit_e)$ holds, this completes the proof of the claim.
    \end{enumerate}

    It remains to show property~\ref{def:feasible-flow:deterministic-split}, i.e. for almost all $\theta$ and all $i\in I$ the equation
    \[
        \outfl[h]_{i,e}(\theta) = \begin{cases}
            \outfl[h]_e(\theta) \cdot \frac{\infl[h]_{i,e}(\xi)}{\infl[h]_e(\xi)}, & \text{if $\infl[h]_e(\xi) > 0$,}\\
            0, & \text{otherwise,}
        \end{cases}
    \]
    holds with $\xi\coloneqq \max \{ \xi  \mid \xi + c^h_e(\xi) = \theta \}$.
    For $\theta < T_e(\phi)$, this property is already induced by the original flow $f$.
    For $\theta > T_e(\phi)$ we have $\xi > \phi$ because of the monotonicity of $T^h_e$ and $T^h_e(\xi) = \theta > T_e(\phi)$.
    Therefore, by definition of our assignments the relations $\infl[h]_{i,e}(\xi) / \infl[h]_{e}(\xi)$ and $\outfl[h]_{i,e}(\theta) / \outfl[h]_{e}(\theta)$ coincide with $g_{i,e}/g_e$ in the case $g_e > 0$.
    For $g_e = 0$, the inflow rates $\infl[h]_{i,e}(\theta)$ and $\infl[h]_{e}(\xi)$ are zero as well.
\end{proof}

We note that in the scenario of Theorem~\ref{thm:extend-edge}, the queue $q_e$ of the transformed flow is given for $\theta \geq \phi$ as follows:
\begin{enumerate}[align=left,leftmargin=*]
    \item[\textbf{Cases I and III.}] If we denote the depletion time by $T_{\depl} \coloneqq \phi + q_e(\phi) / (\capa_e - g_e)$, the queue lengths can be determined using \[
        q_e(\theta) = \begin{cases}
            q_e(\phi) - (\theta - \phi)\cdot (\capa_e - g_e), & \text{for $\theta \leq T_{\depl}$,}\\
            0, & \text{for $\theta \geq T_{\depl}$.}
        \end{cases}
    \]
    \item[\textbf{Case II.}] Here, no queue depletion occurs and for all $\theta \geq \phi$ we have \[
        q_e(\theta) = q_e(\phi) + (\theta - \phi)\cdot \max\{g_e - \capa_e, 0\}.
    \]
\end{enumerate}

The difference between Case I and Case III is that in Case I, $q_e(\phi) = 0$ is allowed, and thus it is possible that $T_{\depl}$ coincides with $\phi$.


\subsection{Encoding Right Constant and Piecewise Linear Functions}

Let us now discuss how the piecewise constant and piecewise linear functions are encoded.
Let $f: \R \rightarrow \R$ be a piecewise linear function given by \[
    f(x) \coloneqq \begin{cases}
        f(\xi_1) +  (x - \xi_1) \cdot s_f & \text{for $x < \xi_1$,} \\
        f(\xi_i) + (x - \xi_i) \cdot \frac{f(\xi_{i+1}) - f(\xi_i)}{\xi_{i+1} - \xi_i} & \text{for $\xi_i \leq x < \xi_{i+1}, i \in \firstN{k-1}$},\\
        f(\xi_k) + (x - \xi_k)\cdot s_l & \text{for $x \geq \xi_k$,}
    \end{cases}
\]
where $\xi_1 < \xi_2 < \cdots < \xi_k$ are the supporting points with $k\geq 1$, and $s_f$ and $s_l$ are the first and last slopes, respectively.
Data~Structure~\ref{data:piecewise-linear} encodes this function by saving the list $[\xi_0,\xi_1,\dots,\xi_k]$ in the attribute \code{times}, $[f(\xi_0), f(\xi_1),\dots, f(\xi_k)]$ in the attribute \code{values} and $s_f$ and $s_l$ in the attributes \code{first_slope} and \code{last_slope}.
Similarly, Data~Structure~\ref{data:right-constant} encodes a right-constant function $f:\R \rightarrow \R$ given by \[
    f(x) \coloneqq \begin{cases}
        v_f, & \text{if $x < \xi_1$ (or $k=0$),} \\
        f(\xi_i), & \text{if $\xi_i \leq x < \xi_{i+1}, i \in \firstN{k-1}$},\\
        f(\xi_k), & \text{if $x \geq \xi_k$,}
    \end{cases}
\]
where $v_f$ is written to the attribute \code{first_value}.
Here, $k=0$ is allowed.
In both cases, an evaluation of the function can be done using a simple binary search in the \code{times} array resulting in a logarithmic complexity in the time dimension $k$.

\vspace{-1em}\hspace{-1em}\begin{minipage}[t]{0.5\textwidth}%
\begin{classdef}[H]%
    \begin{minted}[mathescape, linenos]{python}
class PiecewiseLinear:
  times: List[float]
  values: List[float]
  first_slope: float
  last_slope: float

  #  ... (methods)
\end{minted}
    \caption{\\Piecewise~Linear~Functions\vphantom{Right}}%
    \label{data:piecewise-linear}
\end{classdef}%
\end{minipage}\begin{minipage}[t]{0.5\textwidth}%
\begin{classdef}[H]
    \begin{minted}[mathescape, linenos, stripnl=false]{python}
class RightConstant:
  times: List[float]
  values: List[float]
  first_value: float

  #  ... (methods)

\end{minted}
    \vspace{.084em}
    \caption{\\Right~Constant~Functions}%
    \label{data:right-constant}
\end{classdef}
\end{minipage}\vspace{1em}


In the next section, we will need the following two operations on these functions.
First, we want to be able to extend a piecewise linear function $f$ beginning at some time $\theta \geq \max_{i\in\firstN{k}} \xi_i$ by some slope $s$.
This translates to Algorithm~\ref{alg:extend-piecewise-linear}.
We only add a new entry to the lists \code{times} and \code{values} if $\theta > \max_{i\in\firstN{k}}$.

\begin{algorithm}
  \begin{minted}[mathescape, linenos]{python}
def extend_with_slope(self, time: float, slope: float):
  if time > self.times[-1]:
    val = self.values[-1] + (time - self.times[-1]) * self.last_slope
    self.values.append(val)
    self.times.append(time)
  self.last_slope = slope
  \end{minted}
  \caption{Extension Procedure in \code{class PiecewiseLinear}}
  \label{alg:extend-piecewise-linear}
\end{algorithm}

Similarly, right constant functions should be extendable beginning from some time $\theta \in\R$ with $\theta \geq \sup_{i\in\firstN{k}} \xi_i$ by some value $v\in\R$.
The corresponding procedure is shown in Algorithm~\ref{alg:extend-right-constant}.
Both of these extension procedures have a constant running time.

\begin{algorithm}
  \begin{minted}[mathescape, linenos]{python}
def extend(self, time: float, value: float):
  if len(times) > 0 and time == self.times[-1]:
    self.values[-1] = value
  else:
    self.values.append(value)
    self.times.append(time)
  \end{minted}
  \caption{Extension Procedure in \code{class RightConstant}}
  \label{alg:extend-right-constant}
\end{algorithm}

\subsection{Encoding Feasible Flows}

We now discuss the data structure used for representing and extending partial dynamic flows as defined in Data~Structure~\ref{data:flow}.

\begin{classdef}
    \begin{minted}[mathescape, linenos]{python}
class MultiComFlow
  phi: float
  inflow: Dict[Edge,List[RightConstant]]
  outflow: Dict[Edge, List[RightConstant]]
  queues: Dict[Edge, PiecewiseLinear]
  outflow_changes: PriorityQueue[Tuple[Edge, float]]
  depletions: Dict[Edge, Tuple[float, float, List[float]]]

  #  ... (methods)
\end{minted}
    \caption{Partial Dynamic Flows}
    \label{data:flow}
\end{classdef}

The horizon of such a flow, i.e. the time up to which the flow has been computed, is written to the attribute \code{phi}.
The functions $\infl_{i,e}$ and $\outfl_{i,e}$ correspond to the attributes \code{inflow[e][i]} and \code{outflow[e][i]}, respectively, both of which are objects of the class \code{RightConstant}.

Although, we could compute the queue length of an edge $e$ from these two functions on demand, we allocate 
another attribute \code{queues[e]} for the queue lengths to speed up the extension procedure.
This can be done using an object representing a piecewise linear function because it is the integral of piecewise constant functions.

Next, the priority queue \code{outflow_changes} holds all upcoming events later than \code{phi} where some edge outflow will definitely change.
It saves tuples $(e, \theta)$ with $\theta > \code{phi}$ interpreted as ``\code{outflow[e]} changes at time $\theta$''.
This helps us later as we only want to extend the flow at most as long as no edge outflow rate changes in a single extension phase.

Finally, we have a dictionary \code{depletions} which contains an edge $e$ if there is an upcoming queue depletion at some time $T_{\depl} > \phi$.
In that case, $\code{depletions[e]}$ is a tuple $(T_{\depl}, T_{\depl}+ \transit_e, (g_{i,e})_{i\in I})$ where $(g_{i,e})_{i\in I}$ is the new outflow $(\outfl_{i,e})_{i\in I}$ starting from time $T_{\depl} + \transit_e$.


\subsection{Extension of Feasible Flows}

In this section we discuss how to extend a feasible flow for some time period given new constant inflow rates on a subset of the edges.

In the beginning we usually start with an empty flow representing a feasible flow up to time $0$.
This is an object of the class \code{MultiComFlow} initialized using the operations
\begin{itemize}[left=0pt]
  \setlength{\itemsep}{0em}
\item \code{phi = 0},
\item \code{inflow[e][i] = RightConstant(times=[], values=[], first_value=0)} for all edges \code{e} and commodities \code{i},
\item \code{outflow[e][i] = RightConstant(times=[], values=[], first_value=0)} for all edges \code{e} and commodities \code{i},
\item \code{queues[e] = PiecewiseLinear(times=[0], values=[0], first_slope=0,}\\\code{last_slope=0)} for all edges \code{e},
\end{itemize}
with an empty priority queue \code{outflow_changes} and an empty dictionary \code{depletions}.

We now want to extend this initialized flow in so-called \emph{extension phases}.
That means, given a feasible flow $f$ up to time $\phi$, we want to extend this flow to a feasible flow up to time $\phi + \alpha$ for some small $\alpha > 0$.
During this extension interval $[\phi, \phi+\alpha)$ we keep all edge inflow and outflow rates constant.

We imagine a scenario in which some external mechanism determines edge inflow rates $g\in\R_{\geq 0}^{I\times E}$ to extend $f$ by $\restrict{\infl_{i,e}}{[\phi, \phi+\alpha)} \equiv g_{i,e}$ for some small $\alpha > 0$.
Moreover, we want to choose $\alpha$ at least so small, that no edge outflow rate changes within $[\phi, \phi + \alpha)$.
That way $\bal{i}{v}$ remains constant during this interval and once the node inflow $\sum_{e\in\inEdges{v}}\outfl_{i,e}$ changes, the external mechanism can react to these changes.
This enables the mechanism to pre\-serve the flow conservation property~\ref{def:feasible-flow:flow-conservation} on intermediary nodes.
This external mechanism will be introduced in the next section.

After determining the new inflow rates $(g_{i,e})_{i\in I}$ of an edge $e$ beginning at time $\phi$, we assign $\restrict{\infl_{i,e}}{[\phi,\infty)} \coloneqq g_{i,e}$.
Then we determine the outflow rate of $e$ beginning at time $T_e(\phi) = \phi + \transit_e + q_e(\phi)/\capa_e$ according to properties~\ref{def:feasible-flow:deterministic-split} and~\ref{def:feasible-flow:operate-at-capacity} of Definition~\ref{def:feasible-flow}:

In the extension method we are about to introduce we want to keep track of all future changes of outflow rates of any edge.
This is done by queuing events of this type in the priority queue \code{outflow_changes}.
In all three cases \textbf{I--III} as defined in Theorem~\ref{thm:extend-edge}, the outflow of $e$ changes at time $T_e(\phi)$.
Only in case \textbf{III}, the outflow might change once again at time $T_{\depl} + \transit_e$, if during the interval $(\phi, T_{\depl})$ no other changes to the inflow of $e$ are made.
Hence, in case~\textbf{III} we record a planned change event in the dictionary \code{depletions} for edge $e$ together with the current depletion time as well as the planned change time $T_{\depl} + \transit_e$.

\begin{algorithm}[ht]
    \begin{minted}[linenos, escapeinside=||]{python}
def extend(
  self, new_inflow: Dict[Edge, List[float]], max_ext_time: float
) -> Set[Edge]:
  for e in new_inflow.keys(): |\label{line:extendcases:0}|
    acc_in = sum(new_inflow)
    if acc_in == 0:
      self._extend_case_i(e)
    elif self.queues[e](self.phi) == 0 or acc_in > capacity[e]:
      self._extend_case_ii(e, new_inflow[e])
    else:
      self._extend_case_iii(e, new_inflow[e]) |\label{line:extendcases:1}|

  self.phi = min( |\label{line:extendalpha:0}|
    self.outflow_changes.min_key(),
    min(
      change_time for (_,change_time,_) in self.depletions.values(),
      default=float('inf')
    ),
    max_ext_time
  ) |\label{line:extendalpha:1}|

  self._process_depletions()
    
  changed_edges: Set[Edge] = set() |\label{line:returnedges:0}|
  while self.outflow_changes.min_key() <= self.phi:
      changed_edges.add(self.outflow_changes.pop()[0])
  return changed_edges |\label{line:returnedges:1}|

    \end{minted}
    \caption{Extension Procedure in \code{class MultiComFlow}}
    \label{alg:main-extend}
\end{algorithm}


The main procedure is shown in Algorithm~\ref{alg:main-extend}.
We handle the main three cases \textbf{I}, \textbf{II} and \textbf{III} in different functions, that are called in the  lines~\ref{line:extendcases:0}-\ref{line:extendcases:1}.
These functions extend the queue function \code{queues[e]} and the inflow functions \code{inflow[e][i]} starting from time \code{phi} as well as the outflow functions \code{outflow[e]} starting from time $T_{\code{e}}(\code{phi})$ for all commodities $i$.
Furthermore, they add an event to the queue \code{outflow_changes} to remember that the outflow of edge \code{e} changes at $T_{\code{e}}(\code{phi})$.
Additionally, they update the entry of $\code{e}$ in the dictionary \code{depletions} to reflect whether an upcoming queue depletion will occur with the new edge inflow rate.


Once this is done, we can determine the maximum extension span $\alpha$ and thus the new flow horizon \code{phi} as described in lines~\ref{line:extendalpha:0}-\ref{line:extendalpha:1}.
As we only want to extend at most as long as no edge outflow changes, we take the minimum of such change events.
As queue depletions induced by case~\textbf{III} may also cause outflow rate changes, we also need to consider entries of the dictionary \code{depletions} here.
Finally, we also give the external mechanism the possibility to limit this extension time using the parameter \code{max_ext_time}.

\begin{algorithm}
    \begin{minted}[linenos]{python}
def _process_depletions():
  while min(
      depl_time for (depl_time,_,_) in self.depletions.values(),
      default=float('inf')
    ) <= self.phi:
    e = min(self.depletions, key=lambda e: self.depletions[e][0])
    (depl_time, change_time, new_outflow) = self.depletions.pop(e)
    self.queues[e].extend_with_slope(depl_time, 0)
    if change_time < float('inf'):
      self.outflow_changes.add((e, change_time), change_time)
      for i in range(n):
        self.outflow[e][i].extend(change_time, new_outflow[i])
\end{minted}
\caption{Procedure for Processing Queue Depletions in \code{class MultiComFlow}}
\label{alg:process-depletions}
\end{algorithm}

After determining the extension length via the new flow horizon \code{phi}, we need to process all queue depletions that happen before or at time \code{phi}.
This procedure is depicted in Algorithm~\ref{alg:process-depletions}.
For such a queue depletion of an edge \code{e}, we need to update the queue function \code{queues[e]} which will attain $0$ at its depletion time and should be extended by a $0$ slope.
Furthermore, if the queue depletion induces a change of the edge outflow rate, an appropriate event is added to the priority queue \code{outflow_changes} and the outflow functions \code{outflow[e][i]} are updated for all commodities \code{i}.

After processing all queue depletions, all edge outflow changes that will occur up to the new time horizon \code{phi} have an appropriate entry in \code{outflow_changes}.
Thus, in the main procedure in Algorithm~\ref{alg:main-extend} we can collect all edges whose outflow has changed in the returned set~\code{changed_edges}.
This is described in lines~\ref{line:returnedges:0}-\ref{line:returnedges:1}.

For completeness, we also describe the extension procedures for the three cases \textbf{I}--\textbf{III} in more detail.
Their corresponding implementations are displayed in Algorithm~\ref{alg:extend-cases}.
In all three cases, we first determine the arrival time $T_{\code{e}}(\code{phi})$ when entering the edge at the current time \code{phi} and write the result into the variable \code{arrival}.
Moreover, the pair \code{(e, arrival)} is pushed into the priority queue \code{outflow_changes}.

For case~\textbf{I}, we extend the inflow rates starting at \code{phi} and the outflow rates starting at $T_{\code{e}}(\code{phi})$ with zeros.
If the edge has a positive queue at time \code{phi}, the queue is expected to deplete at time \code{depl_time}.
If this event occurs, no further changes to the outflow rates are necessary, hence we can set the value of \code{e} in the dictionary \code{depletions} to \code{(depl_time, float('inf'), None)}.
On the other hand, if the queue is empty at time \code{phi}, we can simply remove \code{e} from the dictionary, as no depletion will occur.


The case~\textbf{II} is straight-forward:
The new outflow rate starting at $T_{\code{e}}(\code{phi})$ is calculated according to Theorem~\ref{thm:extend-edge} and the assumptions imply that no queue depletion will occur for the given inflow rates.
Hence, we do not need to update the entry of \code{e} in \code{depletions}.
Instead, if an entry of \code{e} exists, we simply remove it.

Case~\textbf{III} can only occur, if a queue depletion is expected.
Again, we calculate the outflow starting at $T_{\code{e}}(\code{phi})$ according to Theorem~\ref{thm:extend-edge} and update the entry in \code{depletions} for \code{e}:
Here, the outflow is expected to change at time $T_{\depl} + \transit_e$ once again where the new outflow rates starting from that time match the new inflow rates. 


\begin{algorithm}
    \begin{minted}[mathescape, linenos]{python}
def _extend_case_i(self, e: Edge):
  cur_queue = self.queues[e](self.phi)
  arrival = self.phi + cur_queue / capacity[e] + travel_time[e]
  self.outflow_changes.push((e, arrival), arrival)
  for i in range(n):
    self.inflow[e][i].extend(self.phi, 0)
    self.outflow[e][i].extend(arrival, 0)

  queue_slope = 0 if cur_queue == 0 else -capacity[e]
  self.queues[e].extend_with_slope(self.phi, queue_slope)
  if cur_queue > 0:
    depl_time = self.phi + cur_queue / capacity[e]
    self.depletions[e] = depl_time, float('inf'), None
  elif e in self.depletions:
    self.depletions.pop(e)


def _extend_case_ii(self, e: Edge, new_inflow: List[float]):
  # cur_queue = [...]; arrival = [...]; self.outflow_changes.push([...])
  for i in range(n):
    self.inflow[e][i].extend(self.phi, new_inflow[i])
    new_out = min(capacity[e], acc_in) * new_inflow[i] / acc_in
    self.outflow[e][i].extend(arrival, new_out)

  queue_slope = max(acc_in - capacity[e], 0)
  self.queues[e].extend_with_slope(self.phi, queue_slope)
  if e in self.depletions:
    self.depletions.pop(e)


def _extend_case_iii(self, e: Edge, new_inflow: List[float]):
  # cur_queue = [...]; arrival = [...]; self.outflow_changes.push([...])
  for i in range(n):
    self.inflow[e][i].extend(self.phi, new_inflow[i])
    new_out = capacity[e] * new_inflow[i] / acc_in
    self.outflow[e][i].extend(arrival, new_out)

  queue_slope = acc_in - capacity[e]
  self.queues[e].extend_with_slope(self.phi, queue_slope)
  depl_time = self.phi + cur_queue / (capacity[e] - acc_in)
  planned_change = depl_time + travel_time[e]
  self.depletions[e] = depl_time, planned_change, new_inflow
\end{minted}
\caption{Extension Procedure for Cases~\textbf{I}--\textbf{III} in \code{class MultiComFlow}}
\label{alg:extend-cases}
\end{algorithm}

\clearpage

\subsection{Computation of Approximated DPEs}\label{subsec:compute-dpes}

We now use the subroutine introduced in the previous section to compute $\varepsilon$-DPEs.
Here, we define the mechanism which decides how the flow is routed from its source to its sink and which defines the constant inflow rates of the extension phases.

As we want each commodity to take shortest paths according to their own traffic forecast, the concept of a predictor is realized as an abstract class as shown in Data Structure~\ref{data:predictor}.
A predictor has an implementation for the method \code{predict}. Attributes of that method are a prediction time \code{phi} and a list \code{old_queues} of past queue length functions of all edges.
This method should return the queue length functions as predicted at time \code{phi} using the past queues \code{old_queues}.
In mathematical terms, it should return $(\hat q_{i,e}(\emptyArg, \bar\theta, q))_{e\in E}$ with $\code{phi}= \bar\theta$ and $\code{old_queues} = q$.

To speed up the calculation of shortest paths, we add a function \code{is_constant} which should return \code{True} if and only if the \code{predict} function of that predictor always returns constant functions.
In that case, we can restrict ourselves to algorithms for static edge costs.

\begin{classdef}
  \begin{minted}[linenos]{python}
class Predictor(ABC):
  @abstractmethod
  def predict(self, phi: float, old_queues: List[PiecewiseLinear]) \
    -> List[PiecewiseLinear]:
    pass
  
  @abstractmethod
  def is_constant(self) -> bool:
    pass
\end{minted}
\caption{The abstract \code{class Predictor}}
\label{data:predictor}
\end{classdef}


In Section~\ref{subsec:implementation-predictors} we will discuss the implementations of the different predictors that have been used throughout the experiments.
Here, we will assume that these implementations are already available.
Each commodity has a predictor assigned to it which is used for its routing decisions.
A commodity's network inflow rate is defined as an arbitrary piecewise constant function saved in the attribute \code{net_inflow}. 
The class definition of a commodity can be seen in Data Structure~\ref{data:commodity}.

\begin{classdef}
    \begin{minted}[mathescape, linenos]{python}
class Commodity:
  source: Node
  sink: Node
  net_inflow: RightConstant
  predictor: Predictor
\end{minted}
\caption{Commodities}%
\label{data:commodity}
\end{classdef}

In the remainder of this section, we introduce another class which encapsulates all the state and procedures necessary for building an $\varepsilon$-DPE: \code{class MultiComFlowBuilder}.
Such a builder is constructed with the following three arguments:
\begin{itemize}
  \item \code{network: Network}. Contains the graph, a list of commodities as well as capacities and travel times of the graph's edges.
  \item \code{predictors: List[Predictor]}. Contains a list of all predictors that are used in the network's commodities.
  \item \code{reroute_interval: float}. The value $\varepsilon$ for building an $\varepsilon$-DPE. 
\end{itemize}

The idea for building such a flow is as follows.
We start with an ``empty'' flow, i.e. a flow with time horizon $\code{phi}=0$.
We calculate shortest paths for each commodity according to predictions taken at time $0$.
Then, we iteratively extend the flow using constant flow rates (with the \code{extend} method of \code{class MultiComFlow})
until some node inflow rate changes or the next reroute time has been reached, i.e. $\code{phi} = k\cdot \varepsilon$ for some $k\in \Z$.
Node inflow rates can only change if some edge outflow rate or the network inflow rate of some commodity change.
The extension procedure of \code{class MultiComFlow} already takes care of changes in the edge outflow rates, so it suffices to keep track of changes in the network inflow rates.  

\begin{classdef}
  \begin{minted}[mathescape, linenos]{python}
class MultiComFlowBuilder:
  network: Network
  predictors: List[Predictor]
  reroute_interval: float
  _flow: MultiComFlow
  _relevant_nodes: Dict[Commodity, Set[Node]]
  _net_inflow_changes: PriorityQueue[Tuple[Commodity, float]]
  _next_reroute_time: float
  _route_time: float
  _costs: Dict[Predictor, Dict[Edge, PiecewiseLinear]]
  _active_edges: Dict[Commodity, Dict[Node, Set[Edge]]]
  _handle_nodes: Set[Node]
\end{minted}
    \caption{The \code{class MultiComFlowBuilder}}%
    \label{data:multi-com-flow-builder}
\end{classdef}

In Data Structure~\ref{data:multi-com-flow-builder} all internal state attributes of the builder are described prefixed with a \code{_}.
Most importantly the actual flow is written to \code{_flow}.
Furthermore, for calculating shortest paths, we save the set of nodes lying on any path from a source to a sink for each commodity in the attribute \code{_relevant_nodes}. 
The priority queue \code{_net_inflow_changes} is initialized with all events of the type $(c, t)$ where the network inflow rate of a commodity $c$ changes at time $t$.
In the attribute \code{_next_reroute_time} we save the next point in time at which routes should be recalculated.
Initially, it has the value $\code{_flow.phi}$.
The attributes \code{_route_time} and \code{_costs} get updated every time new routes are computed:
In \code{_route_time} we save the time at which the latest routes have been computed (and at which time the predictions of queues have been taken) and the attribute \code{_costs[p]} saves the corresponding dynamic edge cost functions $(c_{p,e}(\emptyArg, \bar\theta, q))_{e\in E}$ with $\bar\theta = \code{_route_time}$ for a predictor $\code{p}$.
As calculating shortest paths is computationally expensive, we employ a cache in the attribute \code{_active_edges}.
Here, \code{_active_edges[c]} is a dictionary assigning active outgoing edges $\predE(\bar\theta, \bar\theta, q)\cap \outEdges{v}$ to nodes $v$ for the commodity \code{c}.
These dictionaries are cleared at each reroute time step and filled only on demand, that means only if there is some positive inflow of that commodity into the node which needs to be assigned to outgoing edges.
Finally, the attribute \code{_handle_nodes} is a set containing all nodes whose inflow should be redistributed to outgoing edges in the next extension phase: Only a subset of nodes whose inflow has changed or — at reroute steps — all nodes.
 
\begin{algorithm}
  \begin{minted}[linenos, escapeinside=||]{python}
def build_until(self, horizon: float) -> MultiComFlow:
  graph = self.network.graph
  travel_time = self.network.travel_time
  capacity = self.network.capacity

  while self._flow.phi < horizon: |\label{line:builder:mainloop:0}|
    while self._net_inflow_changes.min_key() <= self._flow.phi: |\label{line:builder:netchange:0}|
      commodity, t = self._net_inflow_changes.pop()
      self._handle_nodes.add(commodity.source) |\label{line:builder:netchange:1}|
    if self._flow.phi >= self._next_reroute_time: |\label{line:builder:reroute:0}|
      predictions = {
        p: p.predict(self._flow.phi, self._flow.queues)
        for p in self.predictors
      }
      self._costs = {
        p: [travel_time[e] + predictions[p][e] / capacity[e]
            for e in graph.edges]
        for p in self.predictors
      }
      self._active_edges = {c: {} for c in self.network.commodities}
      self._route_time = self._next_reroute_time
      self._next_reroute_time += self.reroute_interval
      self._handle_nodes = set(graph.nodes) |\label{line:builder:reroute:1}|

    new_inflow = self._determine_new_inflow() |\label{line:builder:restloop:0}|
    max_ext_time = min(
      self._next_reroute_time, self._net_inflow_changes.min_key()
    )
    changed_edges = self._flow.extend(new_inflow, max_ext_time)
    self._handle_nodes = set(e.node_to for e in changed_edges) |\label{line:builder:mainloop:1}|

  return self._flow
\end{minted}
\caption{The Build Procedure in \code{class MultiComFlowBuilder}}
\label{alg:extend-flow-builder}
\end{algorithm}

Once the user has successfully constructed such a builder and the attributes have been initialized, the user can call the function~\code{builder.build_until} on it which is shown in~Algorithm~\ref{alg:extend-flow-builder}.
This method computes an $\varepsilon$-DPE up to some given time horizon.
In the following, we discuss the details of this method.

The main loop in lines~\ref{line:builder:mainloop:0}--\ref{line:builder:mainloop:1} 
terminates only once the flow has been extended up to the desired time horizon.
In each iteration of this main loop, the flow is extended once with new constant inflow rates using the \code{_flow.extend} method.

Before that, we take care of network inflow rate changes in lines~\ref{line:builder:netchange:0}--\ref{line:builder:netchange:1} by adding all source nodes of commodities whose inflow rate have changed to the set \code{_handle_nodes}.

Furthermore, the lines~\ref{line:builder:reroute:0}--\ref{line:builder:reroute:1} are executed if the routes have to be recalculated.
In that case, we first instantiate new predictions of the queue lengths for each predictor.
From that, we can calculate the cost functions by dividing by the edge capacities and adding the travel times.
After saving these to the attribute \code{_costs}, we clear the cache of the active edges and update \code{_route_time} and \code{_next_reroute_time}.
The set \code{_handle_nodes} gets the set of all nodes assigned, as any node with positive inflow needs to update its outgoing flow distribution according to the new routes.

Lines~\ref{line:builder:restloop:0}--\ref{line:builder:mainloop:1} are executed in every iteration of the loop:
We first determine new constant inflow rates using the current dynamic costs functions in \code{_costs}.
The maximum extension time is the minimum of the next reroute time and the next network inflow change time.
Then, we call \code{_flow.extend} with these two arguments to extend the flow with the new inflow rates until either some edge outflow rate changes or the maximum extension time is reached.
This function call returns the set of edges whose outflow rate changed at the new time \code{_flow.phi}.
Hence, we assign \code{_handle_nodes} the set of target nodes of those edges. 

\begin{algorithm}
  \begin{minted}[linenos]{python}
def _determine_new_inflow(self) -> Dict[Edge, List[float]]:
  new_inflow = {}
  m = len(self.network.commodities)
  for v in self._handle_nodes:
    new_inflow.update({e: [0.] * m for e in v.outgoing_edges})
    for i, commodity in enumerate(self.network.commodities):
      if v not in self._relevant_nodes[commodity] or v == commodity.sink:
        continue
      inflow = sum(self._flow.outflow[e][i](self._flow.phi)
                   for e in v.incoming_edges)
      if v == commodity.source:
        inflow += commodity.net_inflow(self._flow.phi)
      if inflow > 0:
        active_edges = self._get_active_edges(commodity, v)
        distribution = inflow / len(active_edges)
        for e in active_edges:
          new_inflow[e][i] = distribution
  return new_inflow
\end{minted}
\caption{The Inflow Calculation in \code{class MultiComFlowBuilder}}
\label{alg:determine-new-inflow}
\end{algorithm}


Next, we discuss Algorithm~\ref{alg:determine-new-inflow} which takes care of calculating the new constant inflow rates of all outgoing edges of nodes $v$ in~\code{_handle_nodes}.
For all commodities $i$, we calculate the total inflow rate $\bal{i}{v}^+(\phi) = \sum_{e\in\inEdges{v}} \outfl_{e,i}(\phi) + \mathbf{1}_{v=s_i} u_i(\phi)$ into $v$ at time $\phi = \code{_flow.phi}$.
If this value is positive, we retrieve all active outgoing edges for this commodity and node under the current predictions of the commodity's predictor using the method \code{_get_active_edges}.
We then distribute all inflow uniformly into all active outgoing edges. All other outgoing edges get a zero inflow rate.

The final ingredient of the flow builder is the method \code{_get_active_edges} for retrieving the currently active edges for a commodity and a node.
It is shown in Algorithm~\ref{alg:builder:get_active_edges}.
Of course, if the active edges of the corresponding node have already been computed, then we simply return the cached value from~\code{_active_edges}.
Otherwise, we still have to compute them.
We do a case distinction on whether the predictor of a commodity $i$ returns constant queue length functions only.

\newcommand{\dist}{\textrm{dist}}

\begin{algorithm}
  \begin{minted}[linenos, escapeinside=||]{python}
def _get_active_edges(self, c: Commodity, s: Node) -> Set[Edge]:
  if s in self._active_edges[c]:
    return self._active_edges[c][s]

  nodes = self._relevant_nodes[c]
  if self.predictors[c.predictor].is_constant(): |\label{line:getactiveedges:static:0}|
    costs = [cost.values[0] for cost in self._costs[c.predictor]]
    distances = static_dijkstra(c.sink, costs, nodes, reverse=True)
    for v in nodes:
      self._active_edges[c][v] = set(
        e for e in v.outgoing_edges
        if e.node_to in distances.keys() and \
        costs[e.id] + distances[e.node_to] <= distances[v]
      ) |\label{line:getactiveedges:static:1}|
  else:
    self._active_edges[c][s] = get_active_edges(
      self._costs[c.predictor], self._route_time, s, c.sink,
      nodes, self.network.graph, False
    )
  return self._active_edges[c][s]
\end{minted}
\caption{Retrieving Active Edges in \code{class MultiComFlowBuilder}}
\label{alg:builder:get_active_edges}
\end{algorithm}

In the case of constant queue lengths, all edge cost functions $c_{i,e}(\emptyArg,\bar\theta,q)$ are constant as well with $c_{i,e}(\emptyArg,\bar\theta,q)\equivcolon c_{i,e}(\bar\theta,q) \in \R_{>0}$.
If we denote \[
  \dist_{i,v}(\bar\theta, q)\coloneqq \min_{e_1\,\cdots\,e_k\in\paths_{v,t_i}} \sum_{l=1}^k c_{i,e_k}(\bar\theta, q)
\]
as the $\bar\theta$-predicted distance from node $v$ to the sink $t_i$, the arrival functions $l_{i,v}(\emptyArg, \bar\theta, q)$ can be written as \[
  l_{i,v}(\theta, \bar\theta, q) = \theta + \dist_{i,v}(\bar\theta, q),
\]
leaving an edge $e=vw$ $\bar\theta$-predicted active at time $\theta$ if and only if \[
  \dist_{i,v}(\bar\theta, q) = c_{i,e}(\bar\theta, q) + \dist_{i,w}(\bar\theta, q).
\]
Using the static version of the Dijkstra Algorithm on the reverse graph yields the distance vector $(\dist_{i,v}(\bar\theta, q))_{v\in V_i}$.
Thus, as expected we only need a single run of the static Dijkstra Algorithm to compute the active edges of all nodes for that commodity.
This is implemented in lines~\ref{line:getactiveedges:static:0}--\ref{line:getactiveedges:static:1} of Algorithm~\ref{alg:builder:get_active_edges}.
The implementation of the function~\code{static_dijkstra} is not included in this report, however it is straight forward and well covered in standard literature.  

If the queue length functions are not constant, we utilize the algorithm developed in Section~\ref{sec:compute-active-edges}.
This means, that for any node (for which the function \code{_get_active_edges} is called) two instances of the Dynamic Dijkstra Algorithm have to be evaluated once in every routing phase. 


\subsection{Implementation of the Predictors}\label{subsec:implementation-predictors}

In this section we show how the different predictors introduced in Section~\ref{sec:applied-predictors} are implemented.


The simplest predictor is the Zero-Predictor $\predq^\predZ$ which simply returns a constant zero function for each edge as shown in Algorithm~\ref{alg:zero-predictor}.

\begin{algorithm}[H]
  \begin{minted}[linenos, escapeinside=||]{python}
class ZeroPredictor(Predictor):

  def is_constant(self) -> bool:
    return True

  def predict(self, old_queues: List[PiecewiseLinear], phi: float) -> \
      List[PiecewiseLinear]:
    zero_fct = PiecewiseLinear([phi], [0.], 0., 0.)
    return [zero_fct for _ in old_queues]
\end{minted}
\caption{The Zero-Predictor $\predq^\predZ$.}
\label{alg:zero-predictor}
\end{algorithm}

The constant predictor $\predq^\predC$ is slightly more advanced as it predicts constant functions with value $q_e(\phi)$ as shown in Algorithm~\ref{alg:constant-predictor}.
As the function $\predq(\emptyArg, \bar\theta, q)$ is constant for the constant predictor $\predq^\predC$ and for the Zero-predictor $\predq^\predZ$, the method \code{is_constant} returns \code{true}.
For all remaining predictors this is not the case and \code{is_constant} returns \code{false} for them.

\begin{algorithm}[H]
  \begin{minted}[linenos, escapeinside=||]{python}
class ConstantPredictor(Predictor):

  def is_constant(self) -> bool:
    return True

  def predict(self, old_queues: List[PiecewiseLinear], phi: float) -> \
      List[PiecewiseLinear]:
    return [
      PiecewiseLinear([phi], [queue(phi)], 0., 0.)
      for queue in old_queues
    ]
\end{minted}
\caption{The constant predictor $\predq^\predC$.}
\label{alg:constant-predictor}
\end{algorithm}

For the linear predictor and the regularized linear predictor, we assume that the prediction horizon $H>0$ is finite.
The linear predictor can then be initialized using a value \code{horizon} representing $H$.
To determine the gradient $\partial_-q_e(\phi)$, the method \code{gradient} has been implemented for the \code{class PiecewiseLinear}.
The resulting linear predictor is shown in Algorithm~\ref{alg:linear-predictor}.

\begin{algorithm}[H]
  \begin{minted}[linenos, escapeinside=||]{python}
class LinearPredictor(Predictor):
  horizon: float

  def __init__(self, horizon: float):
    super(LinearPredictor, self).__init__()
    self.horizon = horizon

  def is_constant(self) -> bool:
      return False

  def predict(self, old_queues: List[PiecewiseLinear], phi: float) \
      -> List[PiecewiseLinear]:
    times = [phi, phi + self.horizon]
    queues = [None for _ in old_queues]
    for i, queue in enumerate(old_queues):
      val = max(0., queue(phi) + self.horizon * queue.gradient(phi))
      queues[i] = PiecewiseLinear(times, [queue(phi), val], 0., 0.)
    return queues
  \end{minted}
  \caption{The Linear Predictor}
  \label{alg:linear-predictor}
\end{algorithm}

The regularized linear predictor is again a bit easier to implement, as we only evaluate the queue $q_e$ at multiple time steps.
The regularization constant $\delta$ is given as another argument to the constructor of the class as shown in~Algorithm~\ref{alg:reg-linear-predictor}.

\begin{algorithm}[H]
  \begin{minted}[linenos, escapeinside=||]{python}
class RegularizedLinearPredictor(Predictor):
  horizon: float
  delta: float

  def __init__(self, horizon: float, delta: float):
    super(RegularizedLinearPredictor, self).__init__()
    self.horizon = horizon
    self.delta = delta

  def is_constant(self) -> bool:
      return False

  def predict(self, old_queues: List[PiecewiseLinear], phi: float) \
      -> List[PiecewiseLinear]:
    times = [phi, phi + self.horizon]
    queues = [None for _ in old_queues]
    for i, queue in enumerate(old_queues):
      slope = (queue(phi) - queue(phi - self.delta)) / self.delta
      val = max(0., queue(phi) + self.horizon * slope)
      queues[i] = PiecewiseLinear(times, [queue(phi), val], 0., 0.)
    return queues
  \end{minted}
  \caption{The Regularized Linear Predictor}
  \label{alg:reg-linear-predictor}
\end{algorithm}

The most challenging predictor to implement was of course the machine-learned predictor.
After some attempts with the \emph{Tensorflow} framework \cite{tensorflow}, the \emph{Weka} tool \cite{frank2005weka} and the \emph{Deep Graph Library} \cite{dgl} together with the \emph{PyTorch} framework \cite{pytorch}, more detailed experiments were deducted using the \emph{scikit-learn} framework \cite{scikit-learn}, which provides very efficient implementations of linear regression methods.

As explained in Section~\ref{sec:applied-predictors}, for each edge $e=vw$ we want to learn coefficient matrices $W^{e'} \in \R^{k_p \times k_f}$ for neighbouring edges $e'\in N(e)$ and biases $\beta\in\R^{k_f}$ to compute the interpolation points \[
  \predq^\predML_e\left(\bar\theta + j\cdot\delta,\bar\theta,q \right) \coloneqq 
  \left(
  \sum_{e'\in N(e)} \sum_{i = 1}^{k_p} w^{e'}_{i, j} \cdot {q_{e'}}{\left( 
      \bar\theta - (i-1)\cdot\delta
  \right)}
  + \beta_j
  \right)^+,
\]
for $j\in\{1,\dots,k_f\}$, $i\in\{1,\dots,k_p\}$ and $N(e) = \outEdges{v} \cup \{e\} \cup \inEdges{w}$.

For graphs with a large number of edges this quickly gets computationally infeasible. Hence, for such a graph we learn a fixed number of matrices and apply them on all edges.
More specifically, let $\deg^+\coloneqq \max_{v\in V} \abs{ \inEdges{v} }$ be the maximum in-degree and $\deg^-\coloneqq \max_{v\in V} \abs{\outEdges{v}}$ the maximum out-degree of any node.
We learn matrices $W^{+1},\dots,W^{+\deg^+}$, $W^0$, $W^{-1},\dots,W^{-\deg^-}$ and biases $\beta\in\R^{k_f}$.
These generalized parameters can now be applied to predict the queue lengths of any edge $e=vw$:
We arbitrarily order the neighboring edges using $\inEdges{v} \eqqcolon \{ e^{+1},\dots,e^{+\abs{\inEdges{v}}}\}$, $e\eqqcolon e^0$ and $\outEdges{w} \eqqcolon \{ e^{-1},\dots,e^{-\abs{\outEdges{w}}} \}$ and compute \[
  \predq^\predML_e\left(\bar\theta + j\cdot\delta,\bar\theta,q \right) \coloneqq 
  \left(
  \sum_{e^l\in N(e)} \sum_{i = 1}^{k_p} w^{l}_{i, j} \cdot {q_{e^l}}{\left( 
      \bar\theta - (i-1)\cdot\delta
  \right)}
  + \beta_j
  \right)^+.
\]
 
For graphs of any size, we train the linear regression model on samples of queue functions that have previously been computed by the extension procedure of Section~\ref{subsec:compute-dpes}.
In these training flows all commodities exclusively use the constant predictor.

As previously noted, using this prediction method as described by the formulas above does not necessarily lead to a FIFO-compatible predictor.
To force the FIFO-compati\-bility of such a predictor, we have to make sure that the derivative of $\predq^\predML(\emptyArg,\bar\theta,q)$ never subceeds $-\capa_e$.
We do this by sequentially reassigning \[
  \predq^\predML_e\left(\bar\theta + j\cdot\delta,\bar\theta,q \right)
  \coloneqq \max\left\{
    \predq^\predML_e\left(\bar\theta + j\cdot\delta,\bar\theta,q \right), \predq^\predML_e\left(\bar\theta + (j-1)\cdot\delta,\bar\theta,q \right) - \delta\cdot \capa_e
    \right\}
  \]
for $j=1,\dots,k_f$ in a post-processing step.

The full implementation of the predictor for small graphs with $\delta = 1$ can be seen in Algorithm~\ref{alg:ml-predictor}; the predictor for larger graphs is omitted here.
The depicted predictor can be constructed using instances of \code{class sklearn.linear_model.LinearRegression}, i.e. one prelearned linear regression model per edge.
Such a model can be utilized by calling its method \code{predict}.
The variable \code{prediction} in Algorithm~\ref{alg:ml-predictor} then holds the $k_f$ values of the computed interpolation points. 

\begin{algorithm}[H]
  \begin{minted}[linenos, escapeinside=||]{python}
class PerEdgeLinearRegressionPredictor(Predictor):
  network: Network
  past_timesteps: int
  future_timesteps: int

  def __init__(self, models: List[LinearRegression], past_timesteps: int,
      future_timesteps: int, network: Network):
    super().__init__(network)
    self.models = models
    self.past_timesteps = past_timesteps
    self.future_timesteps = future_timesteps
    self.network = network

  def is_constant(self) -> bool:
    return False

  def predict(self, old_queues: List[PiecewiseLinear], phi: float) \ 
      -> List[PiecewiseLinear]:
    times = [phi + t for t in range(0, self.future_timesteps + 1, 1)]
    past_times = [phi - t for t in range(-self.past_timesteps + 1, 1)]
    queues = [None for _ in old_queues]
    for e in self.network.graph.edges:
      model_inputs = 
        [old_queues[ie.id](t) for t in past_times
         for ie in e.node_from.incoming_edges] + \
        [old_queues[oe.id](t) for t in past_times
         for oe in e.node_to.outgoing_edges] + \
        [old_queues[e.id](t) for t in past_times]
      prediction = self.models[e.id].predict([model_inputs])[0]
      cap = self.network.capacity[e.id]
      new_values = [old_queues[e.id](phi)]
      for j in range(1, len(new_values)):
        new_values.append(
          max(prediction[j - 1], new_values[j - 1] - cap, 0.)
        )
      queues[e.id] = PiecewiseLinear(times, new_values, 0., 0.)
    return queues
  \end{minted}
  \caption{The Machine-Learned Predictor $\predq^\predML$ for small graphs}
  \label{alg:ml-predictor}
\end{algorithm}
    