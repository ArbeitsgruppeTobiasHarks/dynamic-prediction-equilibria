\subsection{The Dynamic Dijkstra Algorithm}

The first algorithm we discuss is a simple modification of the Dijkstra Algorithm to determine the earliest arrival times $(l_{s,w}(\theta))_{w\in V'}$ at nodes of some subset $V'\subseteq V$ when departing from a source node $s$ at time $\theta$.
Here, only those nodes are relevant for us that are reachable from $s$ and that can reach $t$.
Moreover, we only need to determine the arrival times of nodes $w$ that can be reached before $t$, i.e. that fulfill $l_{s,w}(\theta) \leq l_{s,t}(\theta)$.
Hence, the set $V'$ consists of all nodes $w$ that lie on a path from $v$ to $t$ and fulfill $l_{s,w}(\theta) \leq l_{s,t}(\theta)$.

\begin{algorithm}[h]
\begin{minted}[mathescape, linenos]{python}
def dynamic_dijkstra(
    theta: float, source: Node, sink: Node, relevant_nodes: Set[Node],
    costs: List[Callable[[float], float]]
) -> Dict[Node, float]:
    arrival_times: Dict[Node, float] = {}
    queue: PriorityQueue[Node] = PriorityQueue([(source, theta)])
    while len(queue) > 0:
        arrival_time, v = queue.min_key(), queue.pop()
        arrival_times[v] = arrival_time
        if v == sink:
            break
        for e in v.outgoing_edges:
            w = e.node_to
            if w in arrival_times.keys() or w not in relevant_nodes:
                continue
            relaxation = arrival_time + costs[e.id](arrival_time)
            if not queue.contains(w):
                queue.push(w, relaxation)
            elif relaxation < queue.key_of(w):
                queue.decrease_key(w, relaxation)
    return arrival_times
\end{minted}
\caption{The Dynamic Dijkstra Algorithm}
\label{alg:dynamic-dijkstra}
\end{algorithm}

Adjusting the classical Dijkstra Algorithm to our setting yields the Dynamic Dijkstra Algorithm as depicted in Algorithm~\ref{alg:dynamic-dijkstra}.

At the heart of the algorithm operates a priority queue consisting of items together with a priority key associated with each item.
This queue has to support the operations \texttt{push(item, key)}, \texttt{min\_key()}, \texttt{pop()}, \texttt{decrease\_key(item, new\_key)} as well as \texttt{contains(item)}.
The operation \texttt{push(item, key)} adds the item \texttt{item} with priority \texttt{key} to the queue, \texttt{min\_key()} returns the minimum key of an item in the queue, \texttt{pop()} returns the item with minimum key and removes it from the queue, \texttt{contains(item)} returns whether \texttt{item} is contained in the queue and the operation \texttt{decrease\_key(item, new\_key)} replaces the priority key associated to the item \texttt{item} with \texttt{new\_key}.


This priority queue holds all discovered nodes where the priority key of a node $w$ is its currently suspected earliest arrival time, an upper bound on $l_{s,w}(\theta)$.


\begin{proposition}
    Given cost functions $c:\R \rightarrow \R_{\geq0}^E$ following the FIFO rule, the Dynamic Dijkstra Algorithm initiated on the source $v\in V$ and a reachable sink $t\in V$ computes the vector $(l_{s,w}(\theta))_{w\in V'}$ with \[
        V' = \{ w\in V \mid \text{$w$ lies on a $v$-$t$-path and $l_{s,w}(\theta) \leq l_{s,t}(\theta)$} \}.
    \]
\end{proposition}
\begin{proof}
    As an invariant for the algorithm we proof, that once a value of a node $w$ is written to \texttt{arrival\_times[w]}, this value coincides with $l_{s,w}(\theta)$.
    In the beginning this is clearly true as no values are written beforehand.
    In the first loop iteration $\texttt{v}$ is the source $s$ and its key $\theta= l_{v,v}(\theta)$ is written to \texttt{arrival\_times[v]}.
    Assume the loop invariant holds before entering loop body another time.
    As nodes are added at most once to the queue, we have $\texttt{v} \neq s$.
    Let $u$ be the any node in whose iteration $\texttt{v}$ was added to the queue or the key of $\texttt{v}$ in the queue was modified.
    The invariant implies $\texttt{arrival\_times[}u\texttt{]} = l_{\texttt{v},u}(\theta)$ and thus $\texttt{arrival\_time} = l_{s,u}(\theta) + c_{u\texttt{v}}(l_{s,u}(\theta)) = T_{u\texttt{v}}(l_{s,u}(\theta)) \geq l_{s,\texttt{v}}(\theta)$.

    Assume $\texttt{arrival\_time} > l_{s,\texttt{v}}(\theta)$ and let $P$ be a shortest $s$-$\texttt{v}$-path at time $\theta$.
    If all nodes of $P$ were available in \texttt{arrival\_times}, then so is the last one $u$ before $\texttt{v}$ in $P$ which would have set the key of \texttt{v} in its iteration to $T_{u\texttt{v}}(l_{s,u}(\theta)) = l_{s,\texttt{v}}(\theta)$.
    Let $u$ be the first node in $P$ that is not available in \texttt{arrival\_times}.
    Because $u$ cannot be the source $s$, the  predecessor $u'$ of $u$ in $P$ must have set the key of $u$ to at most $T_{u'u}(l_{s,u'}(\theta)) \leq T_P(\theta)$.
    As $\texttt{arrival\_time}>l_{s,\texttt{v}}(\theta) = l_P(\theta)$ the key of $u$ in the queue was smaller than the key of \texttt{v}, so the priority queue would have popped $u$ before \texttt{v}.
\end{proof}

A simple binary min-heap together with a lookup table was implemented to support the operations of the queue efficiently.
With this data structure, the worst case running time is logarithmic for the operations \texttt{push(item,key)}, \texttt{pop()} and \texttt{decrease\_key(item, new\_key)} and constant for the operations \texttt{min\_key()} and \texttt{contains(item)}.
Thus, the Dynamic Dijkstra Algorithm terminates with a running time of $\bigO( (\abs{V} + \abs{E}) \cdot \log \abs{V})$.


\subsection{Computing Active Outgoing Edges}

Given a FIFO cost function $c: \R\rightarrow\R_{\geq0}^E$ with a node $s$, a time $\theta\in\R$ and a sink $t$, we now want to compute the active outgoing edges $E(\theta) \cap \outEdges{s}$ of $s$, i.e. the edges $e=sw$ with 
\[
    l_{s,t}(\theta) = l_{w,t}(T_e(\theta)).
\]
Unfortunately, from the arrival times $(l_{s,w}(\theta))_{w\in V'}$ obtained by a simple run of the Dynamic Dijkstra Algorithm, we cannot determine all active edges:
Usually, the idea for determining all active edges would be to do a backward search starting from $t$ on edges $e=vw$ with $l_{s,w}(\theta) = T_e(l_{s,v}(\theta))$ and remember those edges as \emph{active} as they lie on a shortest $s$-$t$-path.
An implementation of this is shown in Algorithm~\ref{alg:backward-search}, where \texttt{arrivals} consists of the labels $(l_{s,w}(\theta))_{w\in V'}$ as returned by the Dynamic Dijkstra Algorithm.

\begin{algorithm}[h]
    \begin{minted}[mathescape, linenos]{python}
def backward_search(
    costs: List[Callable[[float], float]], arrivals: Dict[Node, float],
    source: Node, sink: Node
) -> Set[Edge]:
    active_edges = []
    queue: List[Node] = [sink]
    nodes_enqueued: Set[Node] = {sink}
    while len(queue) > 0:
        w = queue.pop()
        for e in w.incoming_edges:
            v = e.node_from
            if v not in arrivals.keys():
                continue
            if arrivals[v] + costs[e.id](arrivals[v]) <= arrivals[w]:
                if v == source:
                    active_edges.append(e)
                if v not in nodes_enqueued:
                    queue.append(v)
                    nodes_enqueued.add(v)
    return active_edges
    \end{minted}
    \caption{Backward Search}
    \label{alg:backward-search}
\end{algorithm}

However, there might be edges $e=vw$ with $l_{s,w}(\theta) < T_e(l_{s,v}(\theta))$ that lie on a shortest $s$-$t$-path at time $\theta$.
This might be the case if a bottleneck edge $e'$ closer to $t$ has an interval on which $T_{e'}$ is constant.

The following proposition proves that paths found using the described approach are in fact shortest paths.
Moreover, we show that for strong FIFO costs we find all shortest paths.
That means, for strong FIFO costs, the Backward Search Algorithm is correct.

\begin{proposition}
    Let $P=e_1\,\cdots\,e_k$ be a path with $e_i = v_{i-1}v_{i}$ and $v_0 = s, v_k= t$ and let $c:\R\rightarrow\R^E_{\geq0}$ be a cost function following the FIFO rule. Then
    \[ 
        \left(\forall i:\, T_{e_i}(l_{s,v_{i-1}}(\theta)) = l_{s,v_i}(\theta)\right)
        \implies
        T_P(\theta) = l_{s,t}(\theta).
    \]
    If $c$ follows the strong FIFO rule, the statements are equivalent.
\end{proposition}
\begin{proof}
    Assume $T_{e_i}(l_{s,v_{i-1}}(\theta)) = l_{s,v_i}(\theta)$ holds for all $i$.
    Then we have \begin{align*}
        T_P(\theta)
        &= T_P(l_{s,s}(\theta))
        = T_{e_2\,\cdots\,e_{k-1}}(l_{s,v_1}(\theta))
        = \cdots
        = l_{s,v_k}(\theta) = l_{s,t}(\theta).
    \end{align*}

    Let $c$ now follow the strong FIFO rule and assume there is some $i\in\{1,\dots, k\}$ with $T_{e_i}(l_{s,v_{i-1}}(\theta)) > l_{s,v_i}(\theta)$.
    Let $P'$ be a shortest $s$-$v_i$-path at time $\theta$.
    If we extend $P'$ with $e_{i+1}\,\cdots\,e_{k}$ we get an $s$-$t$-path $P''$ with \[
        l_{s,t}(\theta) \leq T_{P''}(\theta)
        = T_{e_{i+1}\,\cdots\,e_k}(l_{s,v_{i}}(\theta))
        < T_{e_{i+1}\,\cdots\,e_k}(T_{e_1\,\cdots\,e_i}(\theta))
        = T_P(\theta),
    \]
    by the strong monotonicity of $T_e$ for all $e\in E$.
\end{proof}

This leaves us with the question of how to find the rest of the active edges for general FIFO cost functions.
For the rest of this section, let $c:\R\rightarrow\R^E_{\geq0}$ follow the FIFO rule with $\lim_{\theta\to-\infty} T_e(\theta) = -\infty$ for all $e\in E$.
The idea we want to exploit now is that once we determined $l_{s,t}(\theta)$, we can do another run of the Dynamic Dijkstra Algorithm on the reverse graph $\rev{G} = (V, \rev{E})$ with $\rev{E}\coloneqq \{ \rev{e} = wv \mid e=vw\in E \}$ to compute the latest departure time to arrive before or at $l_{s,t}(\theta)$ at $t$.

We define the corresponding cost function $\tilde c$ as \[
    \tilde c : \R \rightarrow \R_{\geq0}^{\rev E}, \quad
    \tilde c_{\rev e}(\theta) \coloneqq - \minv{T_e}(-\theta) - \theta.
\]
Note, that $T_e  \geq \id_\R$ and by Proposition~\ref{prop:reversal-props}~\ref{prop:reversal-props:flip-id} we infer $\minv{T_e} \leq \id_\R$.
Therefore, we have $\minv{T_e}(-\theta) \leq -\theta$ and thus $\tilde c_{\rev e}(\theta) \geq 0$.

We denote the traversal times induced by $\tilde c$ by $\tilde T_{\rev e}$ and $\tilde T_{\rev P}$,where $P = \rev{e_k} \, \cdots \, \rev{e_1}$ for $P = e_1\,\cdots\, e_k$,
and the earliest arrival time due to $\tilde c$ as $\tilde l_{v,w}$.
The traversal times fulfill $\tilde T_e = -\minv{T_e}(-\theta)$ which is by Proposition~\ref{prop:reversal-props}~\ref{prop:reversal-props:continuous} strictly increasing.
Hence, $\tilde c$ follows the strong FIFO rule.
For a path $\rev{P} = \rev{e_k}\,\cdots\, \rev{e_1}$ the traversal time yields
\[
    \tilde T_{\rev P} (\theta)
    = \tilde T_{\rev{e_{k-1}}\,\cdots\,\rev{e_1}}(- \minv{T_{e_k}} ( - \theta ))
    = \tilde T_{\rev{e_{k-2}}\,\cdots\,\rev{e_1}}(-\minv{T_{e_{k-1}}} (\minv{T_{e_k}} ( - \theta ))
    = \cdots
    = - \minv{T_P}(-\theta)
\]
and the earliest arrival times are of the form
\[
    \tilde l_{v,w}(\theta)
    = \min_{P\in\paths_{w,v}} \tilde T_{\rev{P}}(\theta)
    = \min_{P\in\paths_{w,v}} - \minv{T_P}(-\theta)
    = - \max_{P\in\paths_{w,v}} \minv{T_P}(-\theta)
    = - \minv{l_{w,v}}(-\theta)
\]

With this setup, we can do a second run of the Dynamic Dijkstra Algorithm to obtain the vector \[
    (\tilde l_{t,w}( - l_{s,t}(\theta) ))_w = (- \minv{l_{t,w}}( l_{s,t}(\theta) ))_w.
\]
Using Lemma~\ref{lem:characterization-active-edges} we can now check whether an outgoing edge $sw\in\outEdges{s}$ of $s$ is active at time $\theta$ by evaluating $T_e(\theta) \leq \minv{l_{t,w}}( l_{s,t}(\theta))$.

\begin{algorithm}[h]
    \begin{minted}[mathescape, linenos]{python}
def get_active_edges(
  costs: List[PiecewiseLinear], theta: float, source: Node, sink: Node,
  relevant_nodes: Set[Node], graph: DirectedGraph, strong_fifo: bool
) -> Set[Edge]:
  if len(source.outgoing_edges) <= 1:
    return source.outgoing_edges
  arrivals = dynamic_dijkstra(
    theta, source, sink, relevant_nodes, costs
  )
  if strong_fifo:
    return backward_search(costs, arrivals, source, sink)
  else: # Second run of Dijkstra on the reverse graph.
    graph.reverse()
    traversals = [cost + identity for cost in costs]
    new_costs: List[Callable[[float], float]] = [
      lambda t: -trav.reversal(-t) - t for trav in traversals
    ]
    neg_departures = dynamic_dijkstra(
      -arrivals[sink], sink, source, relevant_nodes, new_costs
    )
    graph.reverse()
    return [
      e for e in source.outgoing_edges
      if traversals[e.id](theta) <= -neg_departures[e.node_to]
    ]
  \end{minted}
  \caption{Calculating Active Edges}
  \label{alg:calculate-active-edges}
\end{algorithm}


To implement this algorithm, we have to restrict ourselves to cost functions where the reversal of $T_e$ can be evaluated easily.
This is the case, for example, if $c_e$ are piecewise linear functions.
The resulting algorithm for this class of functions can be seen in Algorithm~\ref{alg:calculate-active-edges}.
Here, the flag \texttt{strong\_fifo} is expected to be set only for cost functions following the strong FIFO rule.
For these type of functions, we use the simpler backward search; for  general FIFO functions, we use the approach described above.
Other than that, if $s$ has only up to one outgoing edge, we simply return $\outEdges{s}$.
